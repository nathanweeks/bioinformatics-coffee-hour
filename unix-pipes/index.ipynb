{"metadata":{"kernelspec":{"display_name":"Bash","language":"bash","name":"bash"},"language_info":{"codemirror_mode":"shell","file_extension":".sh","mimetype":"text/x-sh","name":"bash"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Unix Pipes\n### Bioinformatics Coffee Hour - June 16, 2020\n#### Your Host: Nathan Weeks","metadata":{"slideshow":{"slide_type":"slide"}}},{"cell_type":"markdown","source":"## What this lesson will cover\n* Unix pipes in shell scripts to improve efficiency of simple bioinformatics workflows\n* _Example:_ Short-read (FASTQ) alignment to BAM ","metadata":{"slideshow":{"slide_type":"slide"}}},{"cell_type":"markdown","source":"### Software Utilities Used","metadata":{"slideshow":{"slide_type":"subslide"}}},{"cell_type":"markdown","source":"#### curl\n    https://curl.haxx.se/\ncommand line tool and library for transferring data with URLs","metadata":{"slideshow":{"slide_type":"fragment"}}},{"cell_type":"markdown","source":"#### gzip\n    https://www.gnu.org/software/gzip/\npopular data compression program","metadata":{"slideshow":{"slide_type":"fragment"}}},{"cell_type":"markdown","source":"#### fastp\n    https://github.com/OpenGene/fastp\nall-in-one FASTQ preprocessor (QC/adapters/trimming/filtering/splitting/merging...)","metadata":{"slideshow":{"slide_type":"subslide"}}},{"cell_type":"markdown","source":"#### bwa\n    http://bio-bwa.sourceforge.net/\nsoftware package for mapping low-divergent sequences against a large reference genome","metadata":{"slideshow":{"slide_type":"fragment"}}},{"cell_type":"markdown","source":"#### samtools\n    https://github.com/samtools/samtools\ntools... for manipulating [Reading/writing/editing/indexing/viewing] next-generation sequencing data [SAM/BAM/CRAM format]","metadata":{"slideshow":{"slide_type":"fragment"}}},{"cell_type":"markdown","source":"## Motivation\nBioinformatics workflows are usually *big*...\n  - big input files\n  - many workflow **stages**\n    + each workflow stage usually takes as input a file(s) from the previous stage, and produces output file(s) for the next stage\n    + each stage may use a different software tool","metadata":{"slideshow":{"slide_type":"slide"}}},{"cell_type":"markdown","source":"## Example: 1/2 of a variant-calling pipeline\n<img src='https://github.com/harvardinformatics/shortRead_mapping_variantCalling/raw/3965d337e41b6d5fc8b873d7d485fb4bf8528bee/docs/workflowSchematic_fastq2bam.png'>\n\n*source: Brian Arnold, https://github.com/harvardinformatics/shortRead_mapping_variantCalling/ *","metadata":{"slideshow":{"slide_type":"slide"}}},{"cell_type":"markdown","source":"### Definition\n<dl>\n    <dt>file</dt>\n    <dd>An object that can be written to, or read from, or both.</dd>\n</dl>\n\n*source: POSIX.1-2018*","metadata":{"slideshow":{"slide_type":"slide"}}},{"cell_type":"markdown","source":"#### Unix processes start with 3 open \"files\" (connected to a terminal in an interactive shell)\n<dl>\n    <dt>standard input (\"stdin\")</dt>\n    <dd>An input stream usually intended to be used for primary data input.</dd>\n    <dt>standard output (\"stdout\")<dt>\n    <dd>An output stream usually intended to be used for primary data output.</dd>\n    <dt>standard error (\"stderr\")<dt>\n    <dd>An output stream usually intended to be used for diagnostic messages.<dd>\n</dl>\n\n![process](images/process.svg)","metadata":{"slideshow":{"slide_type":"slide"}}},{"cell_type":"markdown","source":"<dl>\n    <dt>filter</dt>\n    <dd>A command whose operation consists of reading data from standard input or a list of input files and writing data to standard output.\n        Typically, its function is to perform some transformation on the data stream.</dd>\n</dl>\n\nsource: POSIX.1-2018_\n\n_Many unix programs act as filters_","metadata":{"slideshow":{"slide_type":"slide"}}},{"cell_type":"markdown","source":"## Example: grep\n\nWhen given only a pattern argument (no file arguments), grep operates as a _filter_, reading input from stdin, and writing output to stdout (_enter CTRL-D to indicate end of input_)\n\n```\n$ grep PATTERN\n```","metadata":{"slideshow":{"slide_type":"fragment"}}},{"cell_type":"markdown","source":"### Redirect stdout to a file\n\nTo write grep's output to a file (instead of a terminal), use the shell redirection operator (`>`)\n\n```\n$ grep PATTERN > matched.txt\n```","metadata":{"slideshow":{"slide_type":"fragment"}}},{"cell_type":"markdown","source":"### Introducing Pipes\nPipes are a form of [Interprocess Communication](https://en.wikipedia.org/wiki/Inter-process_communication) with the following properties:\n* One-way commmunication channel between two _processes_\n  - **process**: a running program\n* Data written (sequentially) by one process (usually to its stdout) is read (sequentially) by another (usually from its stdin)\n* Operating system kernel blocks writer (process in a \"sleep\" state) until data is read by reader\n  + Similarly, reader blocks until writer writes data","metadata":{"slideshow":{"slide_type":"slide"}}},{"cell_type":"markdown","source":"## Why use pipes?\n### Example: Sequential Laundry\n![laundry1](images/laundry1.gif)\n*source: https://cs.stanford.edu/people/eroberts/courses/soco/projects/risc/pipelining/index.html*","metadata":{"slideshow":{"slide_type":"slide"}}},{"cell_type":"markdown","source":"## Why use pipes?\n### Example: Pipelined Laundry\n![laundry2](images/laundry2.gif)\n*source: https://cs.stanford.edu/people/eroberts/courses/soco/projects/risc/pipelining/index.html*","metadata":{"slideshow":{"slide_type":"subslide"}}},{"cell_type":"markdown","source":"## Pipes in Programming Languages \n* The (Unix/Linux/POSIX) shell command language (understood by bash, zsh, sh, and others) has a construct called a pipe (`|` operator)\n* Many other programming languages allow use of pipes in some fashion:\n  - AWK: `command | getline [var]` to read, `print ... > command` to \n  - Python: [subprocess.Popen()](https://docs.python.org/3/library/subprocess.html#replacing-shell-pipeline)\n  - R: `pipe()`\n    + Not to be confused with the pipe `%>%` operator from the magrittr package","metadata":{"slideshow":{"slide_type":"slide"}}},{"cell_type":"markdown","source":"### (shell) Pipeline\n* A sequence of commands separated by the `|` (pipe) operator\n* standard output of the command on the left of the `|` is connected to the standard input of the command to the right of the `|`","metadata":{"slideshow":{"slide_type":"slide"}}},{"cell_type":"markdown","source":"---\n## Examples\n---","metadata":{"slideshow":{"slide_type":"slide"}}},{"cell_type":"markdown","source":"#### Example 1: download FASTA file and compress on-the-fly","metadata":{"slideshow":{"slide_type":"slide"}}},{"cell_type":"code","source":"mkdir -p input\nGENOME_FASTA_URL=https://github.com/harvardinformatics/shortRead_mapping_variantCalling/raw/b120a823c23b1eaf1cfb95ea5d5ca0ce26a50c32/data/genome/Tgut_subseg_renamed.fa\ncurl -sL ${GENOME_FASTA_URL} | gzip -v -9 > input/Tgut_subseg_renamed.fa.gz\nls -lh input/Tgut_subseg_renamed.fa.gz","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Explanation: \n* `curl` downloads the FASTA file from the specified URL and writes it to its stdout.\n* `gzip`, when not given a file argument, reads (uncompressed) data from stdin and writes compressed data to stdout.\n  - The `gzip -v` option prints the compression ratio to stderr_, the `-9` option specififies maximal compression (==more run time, but better compression)\n* The shell output redirection operator (`>`) writes the stdout of `gzip` to a file (Tgut_subseg_renamed.fa.gz)","metadata":{}},{"cell_type":"markdown","source":"#### Example 2: Print the length of each sequence in the compressed FASTA file\nOur FASTA file has one sequence per line. [AWK](https://en.wikipedia.org/wiki/AWK) can generate a tab-separated list of sequence ID and sequence length (\n\n_Problem:_ AWK cannot read a gzip file directly.\n\n_Solution:_ Combine `gzip` options`-d` (decompress) and `-c` (write to stdout), and pipe to awk's stdin:","metadata":{}},{"cell_type":"code","source":"gzip -dc input/Tgut_subseg_renamed.fa.gz |\n  awk '/^>/ { if (len) print len; len = 0; printf(\"%s\\t\", substr($1,2)) }\n       !/^>/ { len+=length }\n       END { printf(\"%i\\n\", len) }'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Fetch sequence reads to align:","metadata":{}},{"cell_type":"code","source":"(cd input && curl -LO 'https://github.com/harvardinformatics/shortRead_mapping_variantCalling/raw/5530f1991da66af82d0213bc3492da8a431a1a92/data/fastq/ERR1013163_[1-2].fastq.gz')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Next, index the genome file so `bwa` can align reads to it:\n\n_Note: `bwa` can index (gzip-)compressed reference sequences_","metadata":{}},{"cell_type":"code","source":"bwa index input/Tgut_subseg_renamed.fa.gz","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Sequence alignment workflow (sequential)\n\n* Output of each stage written as file(s)\n* Command in each stage must be run to completion before next stage is executed","metadata":{}},{"cell_type":"code","source":"set -o xtrace\nmkdir -p orig\ntime (\ncd orig\nln -sf ../input\n# trim reads, generate HTML report\nfastp --in1 input/ERR1013163_1.fastq.gz --in2 input/ERR1013163_2.fastq.gz --out1 ERR1013163_1.fastq-trimmed.gz --out2 ERR1013163_2.fastq-trimmed.gz\n# align reads\nbwa mem input/Tgut_subseg_renamed.fa.gz ERR1013163_1.fastq-trimmed.gz ERR1013163_2.fastq-trimmed.gz > ERR1013163.sam\n# sort alignments by read name\nsamtools sort -n --output-fmt bam -o ERR1013163.bam ERR1013163.sam \n# fill in mate coordinates and insert size in BAM records\nsamtools fixmate -m ERR1013163.bam ERR1013163-fixmate.bam\n# sort by alignment coordinate\nsamtools sort -o ERR1013163-fixmate-sort.bam ERR1013163-fixmate.bam\n# mark duplicate alignments\nsamtools markdup -f markdup.stats --output-fmt-option level=9 ERR1013163-fixmate-sort.bam out.bam\n# index resulting bam file \nsamtools index out.bam\nsamtools stats out.bam > out.bam.stats.txt\n)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Check files created :","metadata":{}},{"cell_type":"code","source":"ls -lh orig","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## A special \"file\": /dev/stdin\n\n* Some utilities either accept an optional file argument (e.g., gzip, awk, most other unix utilities), reading from stdin if no input file is specified\n* Some utilities accept \"-\" in place of either an input or output file argument to mean stdin (or stdout) respectively\n* Other utilities require an actual file argument; e.g. `bwa mem`:\n```\n      bwa mem [options] db.prefix reads.fq [mates.fq]\n```\n  - **reads.fq** is required. However, `bwa mem` reads **reads.fq** sequentially, and can conceptually use a pipe.\n  \n```\n    fastp reads.fq | bwa mem db.prefix /dev/stdin\n```\n  \n**Note: this works only if the utility reads (or writes) the file sequentially**","metadata":{}},{"cell_type":"markdown","source":"### Sequence alignment workflow (pipeline)\n\n* Process in each stage writes output directly to input of another process(es)\n* Processes execute concurrently","metadata":{}},{"cell_type":"code","source":"mkdir -p ex-pipe\ntime (\ncd ex-pipe\nln -s ../input\n# fastp supports interleaved (https://github.com/OpenGene/fastp#output-to-stdout) output\nfastp --in1 input/ERR1013163_1.fastq.gz --in2 input/ERR1013163_2.fastq.gz --stdout 2>/dev/null |\n  # bwa mem requires a FASTQ file operand <in1.fq> (will not take reads from stdin).\n  # /dev/stdin is a special file that represents a process's standard input\n  bwa mem input/Tgut_subseg_renamed.fa.gz /dev/stdin 2> /dev/null |\n    # sort input SAM records by read name (\"-n\"), write uncompressed BAM ((compression) level=0) to stdout\n    # (otherwise, samtools will detect input format & use same output format)\n    samtools sort -n --output-fmt bam --output-fmt-option level=0 |\n      # Usage: samtools fixmate <in.nameSrt.bam> <out.nameSrt.bam>\n      # samtools allows \"-\" to be used in place of \n      samtools fixmate -m - - |\n        # samtools sort reads from stdin and writes to stdout by default\n        samtools sort |\n          samtools markdup -f markdup.stats --output-fmt-option level=9 - - |\n            # samtools index requires an input bam file argument; use /dev/stdin\n            tee out.bam >(samtools index /dev/stdin out.bam.bai) |\n              # samtools stats reads from stdin and writes to stdout by default\n              samtools stats > out.bam.stats.txt\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Much less data written to / read from disk:","metadata":{}},{"cell_type":"code","source":"ls -lh ex-pipe","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's take a closer look at the last stages of the pipeline.\n\nTwo additional tools are being introduced: the [tee](https://en.wikipedia.org/wiki/Tee_(command)) command, and [process substitution](https://en.wikipedia.org/wiki/Process_substitution) ( `>(...)` )\n\n### tee\n\n`tee` duplicates its stdin to one or more files in addition to stdout:\n\n![tee](https://upload.wikimedia.org/wikipedia/commons/2/24/Tee.svg)\n\n*source: Wikipedia*","metadata":{}},{"cell_type":"markdown","source":"```\n... |\n  samtools markdup -f markdup.stats --output-fmt-option level=9 - - |\n    tee out.bam >(samtools index /dev/stdin out.bam.bai) |\n      samtools stats > out.bam.stats.txt\n```\n![pipe](images/pipe.svg)","metadata":{}},{"cell_type":"markdown","source":"# The End!\n## Questions, comments...?","metadata":{}},{"cell_type":"markdown","source":"---\n## Bonus material\n---","metadata":{}},{"cell_type":"markdown","source":"### pipefail\nBy convention, processes return an exit status of 0 to indicate success, and > 0 to indicate failure.\n\nBy default, the exit status of a pipeline is the exit status of the last command in the pipeline:","metadata":{}},{"cell_type":"code","source":"samtools sort foo/bar.sam | head\necho \"exit status: $?\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This is inconvenient when trying to determine if a (Slurm) job script ran successfully, or if it's desired to terminate the script if any command fails (e.g., using `set -o errexit`).\n\nThe `pipefail` option causes the exit status of a pipeline to be the exit status of the last command in the pipeline to have a non-zero exit status:","metadata":{}},{"cell_type":"code","source":"set -o pipefail\nsamtools sort foo/bar.sam | head\necho \"exit status: $?\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Other Terms\n\n### Regular File\n> A file that is a _**randomly accessible**_ sequence of bytes.\n```\n$ ls -lh ERR1013163_1.fastq.gz\n-rw-r--r-- 1 jovyan root 3.8M Jun 10 16:00 ERR1013163_1.fastq.gz\n\n### FIFO (aka \"named pipe\")\n**F**irst **I**n **F**irst **O**ut\n\n> A type of file with the property that data written to such a file is read on a first-in-first-out basis.\n\n_In other words, data are written / read **sequentially**_\n\n### FIFO Example","metadata":{}},{"cell_type":"code","source":"set -o xtrace\nmkfifo test.fifo\nprintf 'line1\\nline2\\nline3\\n' > test.fifo &\nsleep 5\njobs\nsleep 5\ncat test.fifo","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Process Substitution\n`command1 >(command2)` is loosely analogous to:\n```\nmkfifo tmp.fifo\ncommand1 > tmp.fifo &\ncommand2 < tmp.fifo\nrm tmp.fifo\n```","metadata":{}}]}